{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import llm_davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_for_classfication = \"\"\"\n",
    "I want you to classify prompts into one of 6 categories:\n",
    "\n",
    "1.  Image-related\n",
    "    Any prompt that involves generating, modifying, or describing an image, pictures, photos\n",
    "    Examples:\n",
    "    Generate an image of a cat\n",
    "    Create a picture of a dog running through a field\n",
    "    Can you make a photo editing to combine these two faces?\n",
    "    \n",
    "2.  Code-related\n",
    "    Any prompt that involves writing code or explaining code\n",
    "    Examples:\n",
    "    Write a function in Python to calculate the factorial of a number\n",
    "    Can you explain what a for loop does in JavaScript?\n",
    "    \n",
    "3.  Email-sender\n",
    "    Any prompt that involves writing an email, or sending an email\n",
    "    Examples:\n",
    "    Please draft an email to john@example.com asking about the status of the project\n",
    "    Can you write an email to sales@company.com inquiring about pricing for a custom order?\n",
    "    \n",
    "4.  Document, database related\n",
    "    Any prompt that involves updating / deleting documents in a database, listing files in a database, searching and answering questions about files in a database\n",
    "    Examples:\n",
    "    What documents in the database relate to Project X?\n",
    "    Please update the status for entry 12345 in the database to Completed\n",
    "    \n",
    "5.  Selling product\n",
    "    Any prompt that involves selling the product, or buying the product, or enquires about our company product\n",
    "    Examples:\n",
    "    I want to buy a blue model of the Acme Widget. Do you have this in stock?\n",
    "    Can you tell me more about the features of the Deluxe Gizmo? I'm interested in purchasing one.\n",
    "    \n",
    "6.  Question-answering\n",
    "    Any prompt that is asking a question that requires a factual answer\n",
    "    Or any casual talk\n",
    "    If you think it is not Image-related or Code-related, classify it as this one\n",
    "    Examples:\n",
    "    What is the capital of France?\n",
    "    How are you doing today?\n",
    "    Can you recommend a good restaurant in town for dinner?\n",
    "    \n",
    "I will provide a prompt. Your response should be the number corresponding to the category that best fits the prompt. Only respond with '1', '2' or '3', etc.\n",
    "\n",
    "Do not provide any additional explanation or text besides the category number.\n",
    "\n",
    "Now classify this prompt: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I want to write an email to my boss telling him i am sick today and i can't go to work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = llm_davinci(prompt_for_classfication.format(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "match = re.search(r'(\\d)', s)\n",
    "if match:\n",
    "    category = match.group(1)\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file_uploader_routing = \"\"\"\n",
    "Please classify this user prompt into one of the following categories, and extract the relevant information from the prompt. Return the extracted information in JSON format:\n",
    "\n",
    "Search file and answer question - Return {\"purpose\": \"search\", \"query\": \"search query\"}\n",
    "\n",
    "Delete file - Return {\"purpose\": \"delete\", \"file_id\": \"id\"}\n",
    "\n",
    "List files - Return {\"purpose\": \"list\"}\n",
    "\n",
    "\n",
    "Examples:\n",
    "\n",
    "Prompt: What is the best language for AI according to the database?\n",
    "Ans: {\"purpose\": \"search\", \"query\": \"What is the best language for AI?\"}\n",
    "\n",
    "Prompt: Delete file 12345\n",
    "Ans: {\"purpose\": \"delete\", \"file_id\": \"12345\"}\n",
    "\n",
    "Prompt: Show me all files\n",
    "Ans: {\"purpose\": \"list\"}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Delete the file of 7d3ececd-754d-4643-a3c5-bf9199c7f741 from my database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=\"\"\"\n",
    "Current Prompt: {prompt}\n",
    "Ans:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_davinci(prompt_file_uploader_routing+p.format(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "re = json.loads(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re[\"purpose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[\"files\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"remove the file of id 1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_davinci(prompt_file_uploader_routing.format(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"what is inside the database\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_davinci(prompt_file_uploader_routing.format(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_use_in_image = \"\"\"\n",
    "I will provide a prompt describing a request to generate or modify an image. Please parse the prompt and return a JSON object with the following format:\n",
    "\n",
    "{\n",
    "  \"purpose\": \"generate\" or \"modify\",\n",
    "  \"model\": \"mid-journey\" or \"stable diffusion\" \n",
    "}\n",
    "\n",
    "The \"purpose\" should be \"generate\" if the prompt is asking to generate a new image. It should be \"modify\" if the prompt is asking to modify an existing image.\n",
    "\n",
    "The \"model\" should be \"mid-journey\" by default, or \"stable diffusion\" if the prompt specifies that model.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Prompt: Can you generate an image of a cute cat for me?  \n",
    "Ans: {\"purpose\": \"generate\", \"model\": \"mid-journey\"}\n",
    "\n",
    "Prompt: Can you make some changes to the existing cat image?\n",
    "Ans: {\"purpose\": \"modify\", \"model\": \"mid-journey\"}  \n",
    "\n",
    "Prompt: Can you generate an image of a cute dog using stable diffusion?\n",
    "Ans: {\"purpose\": \"generate\", \"model\": \"stable diffusion\"}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Prompt: I want you to generate a new cat sitting in front of tv, with close up to me, using diffusion\\nAns:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=prompt_use_in_image+prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_template = \"\"\"\n",
    "Prompt:{prompt}\n",
    "Ans:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = prompt_use_in_image+Prompt_template.format(prompt=\"change the lower right image to be larger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=llm_davinci(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "r = json.loads(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"purpose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt import prompt_for_image_description\n",
    "prompt = llm_davinci(prompt_for_image_description.format(\n",
    "            prompt=prompt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Prompt_template.format(prompt=\"123456789\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdown format for returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tackle import code_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = code_gen(\"bfs code in python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following is a Python implementation of the breadth-first search algorithm:\\n\\n```python\\ndef bfs(graph, start):\\n  \"\"\"\\n  Performs a breadth-first search on the given graph, starting at the given node.\\n\\n  Args:\\n    graph: A graph represented as a dictionary of adjacency lists.\\n    start: The node to start the search at.\\n\\n  Returns:\\n    A list of nodes in the order they were visited.\\n  \"\"\"\\n\\n  # Create a queue to store the nodes that have yet to be visited.\\n  queue = [start]\\n\\n  # Create a set to store the nodes that have already been visited.\\n  visited = set()\\n\\n  # While there are still nodes to be visited:\\n  while queue:\\n    # Dequeue the next node to be visited.\\n    node = queue.pop(0)\\n\\n    # If the node has not already been visited:\\n    if node not in visited:\\n      # Mark the node as visited.\\n      visited.add(node)\\n\\n      # Add all of the node\\'s neighbors to the queue.\\n      for neighbor in graph[node]:\\n        if neighbor not in visited:\\n          queue.append(neighbor)\\n\\n  # Return the list of nodes in the order they were visited.\\n  return list(visited)\\n```\\n\\nThis algorithm works by first creating a queue to store the nodes that have yet to be visited. The algorithm then dequeues the first node from the queue and marks it as visited. The algorithm then adds all of the node\\'s neighbors to the queue. This process is repeated until the queue is empty. The nodes that are visited in this order are the nodes that are reachable from the starting node.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_newlines_outside_codeblocks(text, replacement):\n",
    "    # Split the text into code and non-code sections\n",
    "    sections = re.split('(```.*?```)', text, flags=re.DOTALL)\n",
    "\n",
    "    for i in range(len(sections)):\n",
    "        # If this section is not a code block\n",
    "        if not sections[i].startswith('```'):\n",
    "            # Replace newlines in this section\n",
    "            sections[i] = sections[i].replace('\\n', replacement)\n",
    "\n",
    "    # Reassemble the text\n",
    "    return ''.join(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = replace_newlines_outside_codeblocks(y, ' <br /> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following is a Python implementation of the breadth-first search algorithm: <br />  <br /> ```python\\ndef bfs(graph, start):\\n  \"\"\"\\n  Performs a breadth-first search on the given graph, starting at the given node.\\n\\n  Args:\\n    graph: A graph represented as a dictionary of adjacency lists.\\n    start: The node to start the search at.\\n\\n  Returns:\\n    A list of nodes in the order they were visited.\\n  \"\"\"\\n\\n  # Create a queue to store the nodes that have yet to be visited.\\n  queue = [start]\\n\\n  # Create a set to store the nodes that have already been visited.\\n  visited = set()\\n\\n  # While there are still nodes to be visited:\\n  while queue:\\n    # Dequeue the next node to be visited.\\n    node = queue.pop(0)\\n\\n    # If the node has not already been visited:\\n    if node not in visited:\\n      # Mark the node as visited.\\n      visited.add(node)\\n\\n      # Add all of the node\\'s neighbors to the queue.\\n      for neighbor in graph[node]:\\n        if neighbor not in visited:\\n          queue.append(neighbor)\\n\\n  # Return the list of nodes in the order they were visited.\\n  return list(visited)\\n``` <br />  <br /> This algorithm works by first creating a queue to store the nodes that have yet to be visited. The algorithm then dequeues the first node from the queue and marks it as visited. The algorithm then adds all of the node\\'s neighbors to the queue. This process is repeated until the queue is empty. The nodes that are visited in this order are the nodes that are reachable from the starting node.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_newline_fix(content: str) -> str:\n",
    "    # Split the content using the code block delimiter\n",
    "    parts = content.split(\"```\")\n",
    "    \n",
    "    # Iterate over the parts and replace \\n with <br /> for every alternate part (i.e., outside code blocks)\n",
    "    for i in range(len(parts)):\n",
    "        if i % 2 == 0:  # This checks if the part is outside a code block\n",
    "            parts[i] = parts[i].replace(\"\\n\", \" <br /> \")\n",
    "        else:\n",
    "            # Replace \\n with actual newlines inside code blocks\n",
    "            parts[i] = parts[i].replace(\"\\\\n\", \"\\n\")\n",
    "    \n",
    "    # Join the parts back together using the code block delimiter\n",
    "    return \"```\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = markdown_newline_fix(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following is a Python implementation of the breadth-first search algorithm: <br />  <br /> ```python\\ndef bfs(graph, start):\\n  \"\"\"\\n  Performs a breadth-first search on the given graph, starting at the given node.\\n\\n  Args:\\n    graph: A graph represented as a dictionary of adjacency lists.\\n    start: The node to start the search at.\\n\\n  Returns:\\n    A list of nodes in the order they were visited.\\n  \"\"\"\\n\\n  # Create a queue to store the nodes that have yet to be visited.\\n  queue = [start]\\n\\n  # Create a set to store the nodes that have already been visited.\\n  visited = set()\\n\\n  # While there are still nodes to be visited:\\n  while queue:\\n    # Dequeue the next node to be visited.\\n    node = queue.pop(0)\\n\\n    # If the node has not already been visited:\\n    if node not in visited:\\n      # Mark the node as visited.\\n      visited.add(node)\\n\\n      # Add all of the node\\'s neighbors to the queue.\\n      for neighbor in graph[node]:\\n        if neighbor not in visited:\\n          queue.append(neighbor)\\n\\n  # Return the list of nodes in the order they were visited.\\n  return list(visited)\\n``` <br />  <br /> This algorithm works by first creating a queue to store the nodes that have yet to be visited. The algorithm then dequeues the first node from the queue and marks it as visited. The algorithm then adds all of the node\\'s neighbors to the queue. This process is repeated until the queue is empty. The nodes that are visited in this order are the nodes that are reachable from the starting node.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install remark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'remark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mremark\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Markdown string with newlines and formatting \u001b[39;00m\n\u001b[1;32m      4\u001b[0m markdown_string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m# Heading\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m**bold** text with _italics_.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'remark'"
     ]
    }
   ],
   "source": [
    "import remark\n",
    "\n",
    "# Markdown string with newlines and formatting \n",
    "markdown_string = \"# Heading\\n\\n**bold** text with _italics_.\"\n",
    "\n",
    "# Parse Markdown with Remark\n",
    "processed = remark.parse(markdown_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
