{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "/home/tsd/mid/benv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from llm import llm_davinci\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import os\n",
    "import uuid\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from llm import llm_davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DB:\n",
    "    def __init__(self, persist_directory):\n",
    "        # Create persist directory\n",
    "        self.persist_directory = persist_directory\n",
    "        os.makedirs(self.persist_directory, exist_ok=True)\n",
    "\n",
    "        # Create Deep Lake vector store with the embedding key\n",
    "        model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "        self.embedding = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", model_kwargs={\"device\": \"cuda\"})\n",
    "        self.db = Chroma(persist_directory= self.persist_directory,\n",
    "                              embedding_function=self.embedding)\n",
    "\n",
    "        # Create QA chain\n",
    "        self.llm = llm_davinci# should be change here later\n",
    "        self.retriever = self.db.as_retriever()\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm, chain_type=\"stuff\", retriever=self.retriever, return_source_documents=True)\n",
    "        self.doc_id_map = {}\n",
    "\n",
    "    def upload(self, file_path, file_type):\n",
    "        if file_type == \"txt\":\n",
    "            loader = TextLoader(file_path)\n",
    "        elif file_type == \"pdf\":\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_type == \"docx\":\n",
    "            loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        elif file_type == \"csv\":\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_type == \"pptx\":\n",
    "            loader = UnstructuredPowerPointLoader(file_path)\n",
    "        else:\n",
    "            print(\"File type not supported\")\n",
    "            return\n",
    "        # may be more here later\n",
    "        parent_id = str(uuid.uuid4())\n",
    "        # child_ids = []\n",
    "\n",
    "        for doc in loader.load():\n",
    "            child_ids = self.db.add_documents([doc])\n",
    "            doc.metadata[\"id\"] = child_ids \n",
    "            \n",
    "            self.doc_id_map[parent_id] = {\n",
    "                \"ids\": child_ids,\n",
    "                \"filename\": os.path.basename(file_path)\n",
    "            }\n",
    "\n",
    "    def delete(self, id):\n",
    "        if id in self.doc_id_map:\n",
    "            info = self.doc_id_map[id] \n",
    "            child_ids = info[\"ids\"]\n",
    "        else: \n",
    "            child_ids = [id]\n",
    "            \n",
    "        del self.doc_id_map[id]\n",
    "        self.db.delete(child_ids)\n",
    "\n",
    "    def search(self, query):\n",
    "        result = self.qa_chain(query)\n",
    "        print(\"****************\")\n",
    "        print(result[\"result\"])\n",
    "        \n",
    "        print(\"****************\")\n",
    "        print(\"\\nSources:\")\n",
    "        for source in result[\"source_documents\"]:\n",
    "            print(source.metadata[\"source\"])\n",
    "\n",
    "    def list_documents(self):\n",
    "            for parent_id, info in self.doc_id_map.items():\n",
    "                print(\"Parent:\")\n",
    "                print(info[\"filename\"])\n",
    "                print(parent_id)\n",
    "                \n",
    "                print(\"Children:\")\n",
    "                for child_id in info[\"ids\"]:\n",
    "                    print(f\"  {child_id}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "db = DB(\"testing_db_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.upload(\"./example_data/InnoLab_visit_developer_kids.pptx\",\"pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent:\n",
      "InnoLab_visit_developer_kids.pptx\n",
      "8fc47137-fae4-45c7-9bb1-bd25c3024d70\n",
      "Children:\n"
     ]
    }
   ],
   "source": [
    "db.list_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      " C language is simpler and more efficient than other languages. It is used for developing operating systems, computer graphics, and games.\n",
      "****************\n",
      "\n",
      "Sources:\n",
      "./example_data/InnoLab_visit_developer_kids.pptx\n"
     ]
    }
   ],
   "source": [
    "db.search(\"For C language, what is the advantage and usage of it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete(\"8fc47137-fae4-45c7-9bb1-bd25c3024d70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.search(\"What computer language are mentioned?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.search(\"What are the computer language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.search(\"What is ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.search(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import MongoDBChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"mongodb+srv://projectvpn39:kDir8fgavrwmXhUN@cluster0.bdqojht.mongodb.net/?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = MongoDBChatMessageHistory(\n",
    "\n",
    "    connection_string=connection_string, session_id=\"team-testing\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.chat_memory.add_user_message(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.to_dict()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace the placeholder values with your actual MongoDB connection details\n",
    "client = MongoClient(\"mongodb+srv://projectvpn39:kDir8fgavrwmXhUN@cluster0.bdqojht.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = client[\"database\"]\n",
    "collection = db[\"collection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ConversationBufferMemory class\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory.chat_memory:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the memory object to a dictionary\n",
    "memory_dict = {\n",
    "    \"chat_memory\": memory.chat_memory.messages,\n",
    "    \"output_key\": memory.output_key,\n",
    "    \"input_key\": memory.input_key,\n",
    "    \"return_messages\": memory.return_messages,\n",
    "    \"human_prefix\": memory.human_prefix,\n",
    "    \"ai_prefix\": memory.ai_prefix,\n",
    "    \"memory_key\": memory.memory_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the memory object into the MongoDB collection\n",
    "collection.insert_one(memory_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "\n",
    "from power_automate import send_email\n",
    "from llm import llm_azure_gpt35\n",
    "\n",
    "from llm import internaL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain(llm=llm_azure_gpt35)\n",
    "toolss = load_tools([\"wikipedia\"], llm=llm_azure_gpt35)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about maths, but not anything else\",\n",
    "        return_direct=True,  # help you to correct the prompt\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Internal Database\",\n",
    "        description=\"useful for when you need to answer questions about alphabet company annual report\",\n",
    "        func=internaL_db.run,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Send Email\",\n",
    "        func=send_email,\n",
    "        description=\"\"\"\"\n",
    "        Useful for sending the email, please just send what is the intention of the email, and who is the target to send\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "tools.append(toolss[0])\n",
    "toolls = load_tools([\"google-search\"])\n",
    "# tools[0].description = \"This tool allows you to search the web using the Google Search API. Useful for when you need to answer questions about current events\"\n",
    "tools.append(toolls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(data, memory):\n",
    "    # {'model': {'id': 'Vicuna', 'name': 'Vicuna', 'maxLength': 96000, 'tokenLimit': 32768}, 'systemPrompt': \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\", 'temperature': 0.7, 'key': '', 'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}]}\n",
    "    # print(data)\n",
    "    agent_chain = initialize_agent(\n",
    "        tools, llm_azure_gpt35, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "    response = agent_chain.run(input=data)\n",
    "    # print(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"HI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(data, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory.chat_memory:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory.chat_memory.messages:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def mongo_to_conversation(mongo_history):\n",
    "  conversation_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "  \n",
    "  # Set MongoDB chat history \n",
    "  conversation_memory.chat_memory.messages = mongo_history.messages\n",
    "\n",
    "#   # Initialize other fields\n",
    "#   conversation_memory.session_id = session_id\n",
    "\n",
    "  return conversation_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.memory import MongoDBChatMessageHistory\n",
    "connection_string = \"mongodb+srv://projectvpn39:kDir8fgavrwmXhUN@cluster0.bdqojht.mongodb.net/?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = MongoDBChatMessageHistory(\n",
    "\n",
    "    connection_string=connection_string, database_name=\"langchain\", collection_name=\"chat_history\", session_id=\"team-testing\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mongo_to_conversation(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.chat_memory.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from llm import llm_azure_gpt35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ConversationSummaryBufferMemory(llm=llm_azure_gpt35,max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('human_prefix', 'Human')\n",
      "('ai_prefix', 'AI')\n",
      "('llm', AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-35-turbo', temperature=0.0, model_kwargs={}, openai_api_key='f96c629ba6874b2aaa7569acfea2162c', openai_api_base='https://pocsc.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=True, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='gpt35', openai_api_type='azure', openai_api_version='2023-03-15-preview'))\n",
      "('prompt', PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:', template_format='f-string', validate_template=True))\n",
      "('summary_message_cls', <class 'langchain.schema.messages.SystemMessage'>)\n",
      "('chat_memory', ChatMessageHistory(messages=[]))\n",
      "('output_key', None)\n",
      "('input_key', None)\n",
      "('return_messages', False)\n",
      "('max_token_limit', 100)\n",
      "('moving_summary_buffer', '')\n",
      "('memory_key', 'history')\n"
     ]
    }
   ],
   "source": [
    "for i in y:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "\n",
    "from power_automate import send_email\n",
    "from llm import llm_azure_gpt35\n",
    "\n",
    "from llm import internaL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain(llm=llm_azure_gpt35)\n",
    "toolss = load_tools([\"wikipedia\"], llm=llm_azure_gpt35)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about maths, but not anything else\",\n",
    "        return_direct=True,  # help you to correct the prompt\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Internal Database\",\n",
    "        description=\"useful for when you need to answer questions about alphabet company annual report\",\n",
    "        func=internaL_db.run,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Send Email\",\n",
    "        func=send_email,\n",
    "        description=\"\"\"\"\n",
    "        Useful for sending the email, please just send what is the intention of the email, and who is the target to send\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "tools.append(toolss[0])\n",
    "toolls = load_tools([\"google-search\"])\n",
    "# tools[0].description = \"This tool allows you to search the web using the Google Search API. Useful for when you need to answer questions about current events\"\n",
    "tools.append(toolls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(data, memory,mogodb):\n",
    "    # {'model': {'id': 'Vicuna', 'name': 'Vicuna', 'maxLength': 96000, 'tokenLimit': 32768}, 'systemPrompt': \"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.\", 'temperature': 0.7, 'key': '', 'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}]}\n",
    "    # print(data)\n",
    "    mogodb.add_user_message(data)\n",
    "    agent_chain = initialize_agent(\n",
    "        tools, llm_azure_gpt35, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "    response = agent_chain.run(input=data)\n",
    "    mogodb.add_ai_message(response)\n",
    "    # print(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"What is the weather like today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(data, c ,message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c.chat_memory.messages:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in memory.chat_memory.messages:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
