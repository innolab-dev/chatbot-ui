{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "codey = ChatVertexAI(model_name='codechat-bison@001', max_output_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "/home/tsd/mid/benv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "\n",
    "# from power_automate import send_email\n",
    "from llm import llm_azure_gpt35, bison_chat, codey\n",
    "\n",
    "from llm import internaL_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_error(error) -> str:\n",
    "\n",
    "    return str(error)[:1024].strip(\"Could not parse LLM output: ```{\").strip(\"}```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsd/mid/benv/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:50: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_math_chain = LLMMathChain(llm=llm_azure_gpt35)\n",
    "toolss = load_tools([\"wikipedia\"], llm=llm_azure_gpt35)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about maths, but not anything else\",\n",
    "        return_direct=True,  # help you to correct the prompt\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Internal Database\",\n",
    "        description=\"useful for when you need to answer questions about alphabet company annual report\",\n",
    "        func=internaL_db.run,\n",
    "    ),\n",
    "    # Tool(\n",
    "    #     name=\"Send Email\",\n",
    "    #     func=send_email,\n",
    "    #     description=\"\"\"\"\n",
    "    #     Useful for sending the email, please just send what is the intention of the email, and who is the target to send\n",
    "    #     \"\"\"\n",
    "    # ),\n",
    "]\n",
    "\n",
    "\n",
    "tools.append(toolss[0])\n",
    "toolls = load_tools([\"google-search\"])\n",
    "# tools[0].description = \"This tool allows you to search the web using the Google Search API. Useful for when you need to answer questions about current events\"\n",
    "tools.append(toolls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversationID = \"teams-testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "mem, mongo = memory(conversationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, bison_chat, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                                       verbose=True, memory=mem, handle_parsing_errors=_handle_error, max_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"can you generate the code for bfs in python to me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```python\n",
      "def bfs(graph, start):\n",
      "  \"\"\"\n",
      "  Breadth-first search algorithm.\n",
      "\n",
      "  Parameters:\n",
      "    graph: A graph represented as a dictionary of dictionaries. The keys of the\n",
      "      outer dictionary are the nodes in the graph, and the values are dictionaries\n",
      "      mapping each node to its adjacent nodes.\n",
      "    start: The node to start the search from.\n",
      "\n",
      "  Returns:\n",
      "    A list of nodes in the order they were visited during the search.\n",
      "  \"\"\"\n",
      "\n",
      "  # Create a queue to store the nodes that we need to visit.\n",
      "  queue = [start]\n",
      "\n",
      "  # Create a set to store the nodes that we have already visited.\n",
      "  visited = set()\n",
      "\n",
      "  # While there are nodes in the queue:\n",
      "  while queue:\n",
      "    # Dequeue the next node to visit.\n",
      "    node = queue.pop(0)\n",
      "\n",
      "    # Add the node to the set of visited nodes.\n",
      "    visited.add(node)\n",
      "\n",
      "    # For each adjacent node of the current node:\n",
      "    for adjacent_node in graph[node]:\n",
      "      # If the adjacent node has not been visited yet, add it to the queue.\n",
      "      if adjacent_node not in visited:\n",
      "        queue.append(adjacent_node)\n",
      "\n",
      "  # Return the list of nodes in the order they were visited.\n",
      "  return list(visited)\n",
      "```\u001b[0m\n",
      "Observation: ython\n",
      "def bfs(graph, start):\n",
      "  \"\"\"\n",
      "  Breadth-first search algorithm.\n",
      "\n",
      "  Parameters:\n",
      "    graph: A graph represented as a dictionary of dictionaries. The keys of the\n",
      "      outer dictionary are the nodes in the graph, and the values are dictionaries\n",
      "      mapping each node to its adjacent nodes.\n",
      "    start: The node to start the search from.\n",
      "\n",
      "  Returns:\n",
      "    A list of nodes in the order they were visited during the search.\n",
      "  \"\"\"\n",
      "\n",
      "  # Create a queue to store the nodes that we need to visit.\n",
      "  queue = [start]\n",
      "\n",
      "  # Create a set to store the nodes that we have already visited.\n",
      "  visited = set()\n",
      "\n",
      "  # While there are nodes in the queue:\n",
      "  while queue:\n",
      "    # Dequeue the next node to visit.\n",
      "    node = queue.pop(0)\n",
      "\n",
      "    # Add the node to the set of visited nodes.\n",
      "    visited.add(node)\n",
      "\n",
      "    # For each adjacent node of the current node:\n",
      "    for adjacent_node in graph[node]:\n",
      "      # If the adjacent node has not been visited yet, add it to the queue.\n",
      "      if adjacent_node not in visited:\n",
      "\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Here is the code for bfs in python:\n",
      "\n",
      "```python\n",
      "def bfs(graph, start):\n",
      "  \"\"\"\n",
      "  Breadth-first search algorithm.\n",
      "\n",
      "  Parameters:\n",
      "    graph: A graph represented as a dictionary of dictionaries. The keys of the\n",
      "      outer dictionary are the nodes in the graph, and the values are dictionaries\n",
      "      mapping each node to its adjacent nodes.\n",
      "    start: The node to start the search from.\n",
      "\n",
      "  Returns:\n",
      "    A list of nodes in the order they were visited during the search.\n",
      "  \"\"\"\n",
      "\n",
      "  # Create a queue to store the nodes that we need to visit.\n",
      "  queue = [start]\n",
      "\n",
      "  # Create a set to store the nodes that we have already visited.\n",
      "  visited = set()\n",
      "\n",
      "  # While there are nodes in the queue:\n",
      "  while queue:\n",
      "    # Dequeue the next node to visit.\n",
      "    node = queue.pop(0)\n",
      "\n",
      "    # Add the node to the set of visited nodes.\n",
      "    visited.add(node)\n",
      "\n",
      "    # For each adjacent node of the current node:\n",
      "    for adjacent_node in graph[node]:\n",
      "      # If the adjacent node has not been visited yet, add it to the queue.\n",
      "      if adjacent_node not in visited:\n",
      "        queue.append(adjacent_node)\n",
      "\n",
      "  # Return the list of nodes in the order they were visited.\n",
      "  return list(visited)\n",
      "```\"\n",
      "}\n",
      "\u001b[0m\n",
      "Observation: json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Here is the code for bfs in python:\n",
      "\n",
      "```python\n",
      "def bfs(graph, start):\n",
      "  \"\"\"\n",
      "  Breadth-first search algorithm.\n",
      "\n",
      "  Parameters:\n",
      "    graph: A graph represented as a dictionary of dictionaries. The keys of the\n",
      "      outer dictionary are the nodes in the graph, and the values are dictionaries\n",
      "      mapping each node to its adjacent nodes.\n",
      "    start: The node to start the search from.\n",
      "\n",
      "  Returns:\n",
      "    A list of nodes in the order they were visited during the search.\n",
      "  \"\"\"\n",
      "\n",
      "  # Create a queue to store the nodes that we need to visit.\n",
      "  queue = [start]\n",
      "\n",
      "  # Create a set to store the nodes that we have already visited.\n",
      "  visited = set()\n",
      "\n",
      "  # While there are nodes in the queue:\n",
      "  while queue:\n",
      "    # Dequeue the next node to visit.\n",
      "    node = queue.pop(0)\n",
      "\n",
      "    # Add the node to the set of visited nodes.\n",
      "    visited.add(node)\n",
      "\n",
      "    # For each adjacent node of the current node:\n",
      "    for adjacent_node in graph[node]:\n",
      "      # If the adjac\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_chain.run(input=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent stopped due to iteration limit or time limit.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=codey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function that identifies if the number is a prime number?\"\n",
    "\n",
    "s = llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a Python function that identifies if the number is a prime number:\n",
      "\n",
      "```\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    if n <= 3:\n",
      "        return True\n",
      "    if n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    for i in range(5, int(n ** 0.5) + 2, 6):\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "    return True\n",
      "```\n",
      "\n",
      "This function works by first checking if the number is less than or equal to 1. If it is, then it is not prime. If it is greater than or equal to 2, then it is prime. If it is equal to 2 or 3, then it is also prime. If it is greater than 3, then the function checks if the number is divisible by 2 or 3. If it is, then it is not prime. If it is not divisible by 2 or 3, then the function checks if the number is divisible by any number in the range of 5 to the square root of the number plus 2. If it is divisible by any number in this range, then it is not prime. If it is not divisible by any number in this range, then it is prime.\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
